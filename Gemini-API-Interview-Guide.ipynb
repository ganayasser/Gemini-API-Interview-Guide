{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3905319,"sourceType":"datasetVersion","datasetId":2319697}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style= \"font-size:18px; background-color: #4094f7; border: 1px solid ##E1AFD1\n; padding: 15px; border-radius: 8p\">\n  <b>Ready to unlock the secrets of Gemini? Let's embark on your API key journey üëÄ! </b>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<a href=\"https://ibb.co/xhg80bN\">\n    <img src=\"https://i.ibb.co/6YtJxSk/Build-with-Gemini-dk-16-9-1-width-1200-format-webp.webp\" alt=\"gemini\" style=\"width: 100%; max-width: 900px; border: 0;\">\n</a>","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color: #4094f7; font-family:'Handlee', cursive; font-size: 24px; \"> Welcome to this notebook ‚ú® </span>\n\n<div style=\"font-family: 'Arial', cursive; font-size: 15px; color: #FFAACF;\">\n  Where we dive into the powerful capabilities of the Gemini API for AI and data science. Here, you'll discover how the Gemini API can elevate your interview performance with practical questions tailored to your experience level and real-life scenarios. With expert answers provided,and also recommended courses to further enhance your skills, this guide is perfect for advancing your AI models and optimizing data workflows, equipping you with the tools and knowledge needed for success.<br><br>\n<span style=\"color: #4094f7; font-family: 'Handlee', cursive; font-size: 20px; \">    Enjoy the Ride üîç! </span>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:#4094f7; font-size: 22px; \">01. Install required libraries</span>\n\n<div style=\"color: #FFAACF; font-size: 16px;\">\n    \nlangchain library facilitates the development of language model-powered applications by providing tools for chaining together large language models with other services and utilities. <br> \n    \nSentence_transformers library is used for embedding sentences into high-dimensional vectors, enabling tasks such as semantic search, clustering, and classification through pre-trained models.\n</div>\n","metadata":{}},{"cell_type":"code","source":"!pip install langchain\n!pip install sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:45:30.143630Z","iopub.execute_input":"2024-08-27T09:45:30.144047Z","iopub.status.idle":"2024-08-27T09:45:55.596610Z","shell.execute_reply.started":"2024-08-27T09:45:30.143986Z","shell.execute_reply":"2024-08-27T09:45:55.595307Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.14)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.35)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.104)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.2)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (2.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\nRequirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.4.0+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.14.0)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.24.6)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.7.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <span style=\"color:#4094f7; font-size: 22px;\">02. Import libraries</span>\n","metadata":{}},{"cell_type":"code","source":"# Import required libraries\nfrom kaggle_secrets import UserSecretsClient\nfrom IPython.display import Markdown\nimport textwrap\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom langchain.prompts import PromptTemplate\nimport google.generativeai as genai\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-27T09:45:55.602515Z","iopub.execute_input":"2024-08-27T09:45:55.602848Z","iopub.status.idle":"2024-08-27T09:45:59.443263Z","shell.execute_reply.started":"2024-08-27T09:45:55.602811Z","shell.execute_reply":"2024-08-27T09:45:59.442235Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"\n# <span style=\"color:#4094f7; font-size: 22px;\">03. Gemini API Key Initialization</span>\n\n<span style=\"font-size:16px; color:#FFAACF;\">\n    \n    Just follow the steps ‚Ü¥ \n    \n1. Go to [the Google AI Studio](https://ai.google.dev/aistudio)\n2. Sign in with your Google account\n3. Navigate to the API section\n4. Click on \"Get API key\"\n5. Follow the prompts to create a new project or select an existing one\n6. Your API key will be generated and displayed \n</span>","metadata":{}},{"cell_type":"code","source":"# Initialize API key for Google Gemini API\nuser_secrets = UserSecretsClient()\napiKey = user_secrets.get_secret(\"GEMINI_API_KEY\")\ngenai.configure(api_key = apiKey)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:45:59.444676Z","iopub.execute_input":"2024-08-27T09:45:59.445441Z","iopub.status.idle":"2024-08-27T09:45:59.737647Z","shell.execute_reply.started":"2024-08-27T09:45:59.445392Z","shell.execute_reply":"2024-08-27T09:45:59.736405Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#4094f7; font-size: 22px;\">04. Load Dataset </span>\n\n<div style=\"font-size:16px; color:#FFAACF;\">\n    \nAbout Dataset:<br>\n    \nA Data Science interview calls for a rigorous interview process where the candidates are judged on various aspects such as technical and programming skills, knowledge of methods, and clarity of basic concepts.<br>\n    \nIn this dataset, you can find three categories ['fresh', 'intermediate', 'senior'] of question base data.\n</div>\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd \n# Load the dataset\ntrain_df = pd.read_csv('/kaggle/input/data-science-interview-question-data/datascience_questions.csv')\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:45:59.741198Z","iopub.execute_input":"2024-08-27T09:45:59.741695Z","iopub.status.idle":"2024-08-27T09:45:59.757474Z","shell.execute_reply.started":"2024-08-27T09:45:59.741643Z","shell.execute_reply":"2024-08-27T09:45:59.756321Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(80, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"\n# <span style=\"color:#4094f7; font-size: 22px;\">05. Display Dataset </span>\n","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:45:59.758941Z","iopub.execute_input":"2024-08-27T09:45:59.759410Z","iopub.status.idle":"2024-08-27T09:45:59.774527Z","shell.execute_reply.started":"2024-08-27T09:45:59.759363Z","shell.execute_reply":"2024-08-27T09:45:59.773521Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Sr. no Category                                           Questions\n0       1     fresh  What Are the Different Types of Machine Learning?\n1       2     fresh    What is Overfitting, and How Can You Avoid It?¬†\n2       3     fresh  What is ‚Äòtraining Set‚Äô and ‚Äòtest Set‚Äô in a Mac...\n3       4     fresh  How Do You Handle Missing or Corrupted Data in...\n4       5     fresh  How Can You Choose a Classifier Based on a Tra...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sr. no</th>\n      <th>Category</th>\n      <th>Questions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>fresh</td>\n      <td>What Are the Different Types of Machine Learning?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>fresh</td>\n      <td>What is Overfitting, and How Can You Avoid It?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>fresh</td>\n      <td>What is ‚Äòtraining Set‚Äô and ‚Äòtest Set‚Äô in a Mac...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>fresh</td>\n      <td>How Do You Handle Missing or Corrupted Data in...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>fresh</td>\n      <td>How Can You Choose a Classifier Based on a Tra...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"category_list = train_df['Category '].unique().tolist()\nprint(category_list)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:45:59.775785Z","iopub.execute_input":"2024-08-27T09:45:59.776197Z","iopub.status.idle":"2024-08-27T09:45:59.782482Z","shell.execute_reply.started":"2024-08-27T09:45:59.776160Z","shell.execute_reply":"2024-08-27T09:45:59.781381Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['fresh', 'intermediate', 'senior']\n","output_type":"stream"}]},{"cell_type":"code","source":"sampled_df = train_df.sample(n=10)\n\n# Iterate through the sampled DataFrame and print questions and categories\nfor index, row in sampled_df.iterrows():\n    print('Question Level:', row['Category '])\n    print(row['Questions'])\n    print('-' * 60)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:45:59.783995Z","iopub.execute_input":"2024-08-27T09:45:59.784658Z","iopub.status.idle":"2024-08-27T09:45:59.796671Z","shell.execute_reply.started":"2024-08-27T09:45:59.784620Z","shell.execute_reply":"2024-08-27T09:45:59.795575Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Question Level: intermediate\nWhat are Loss Function and Cost Functions? Explain the key Difference Between them?\n------------------------------------------------------------\nQuestion Level: senior\nWhat is a Box-Cox transformation?\n------------------------------------------------------------\nQuestion Level: senior\nBoth being Tree-based Algorithms, how is Random Forest different from Gradient Boosting Machine (GBM)?\n------------------------------------------------------------\nQuestion Level: fresh\nWhat are Recommender Systems?\n------------------------------------------------------------\nQuestion Level: senior\nWhat is ROC Curve and what does it represent?\n------------------------------------------------------------\nQuestion Level: fresh\nWhat is Clustering?\n------------------------------------------------------------\nQuestion Level: senior\nIn Machine Learning, for how many classes can Logistic Regression be used?\n------------------------------------------------------------\nQuestion Level: intermediate\nConsidering a Long List of Machine Learning Algorithms, given a Data Set, How Do You Decide Which One to Use?\n------------------------------------------------------------\nQuestion Level: senior\nWhat is Marginalisation? Explain the process.\n------------------------------------------------------------\nQuestion Level: intermediate\nWhat is P-value?\n------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <span style=\"color:#4094f7; font-size: 22px;\">06.  Text Cleaning </span>\n\n<span style=\"font-size:16px; color:#FFAACF;\">\n    \n1. Removing the specified end-of-sentence token.\n2. Removing double asterisks (**).\n3. Removing the pad token.\n4. Replacing double spaces with single spaces.\n5. Stripping leading and trailing spaces. \n</span>","metadata":{}},{"cell_type":"code","source":"def clean_text(txt, EOS_TOKEN):\n    \"\"\"Clean text by removing specific tokens and redundant spaces.\"\"\"\n    txt = (txt\n           .replace(EOS_TOKEN, \"\")  \n           .replace(\"**\", \"\")      \n           .replace(\"<pad>\", \"\") \n           .replace(\"  \", \" \")    \n          ).strip()                \n    return txt","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:45:59.798124Z","iopub.execute_input":"2024-08-27T09:45:59.798521Z","iopub.status.idle":"2024-08-27T09:45:59.808087Z","shell.execute_reply.started":"2024-08-27T09:45:59.798484Z","shell.execute_reply":"2024-08-27T09:45:59.806818Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#4094f7; font-size: 22px;\">07. Answer Generation </span>","metadata":{}},{"cell_type":"code","source":"def generate_answer_with_api(question):\n    \"\"\"Generate an answer using the external API.\"\"\"\n    try:\n        model = genai.GenerativeModel('gemini-pro')\n        response = model.generate_content(question)  \n        answer = response.text  \n        return clean_text(answer, '')  \n    except Exception as e:\n        print(f\"Error generating answer with API: {e}\")\n        return \"Sorry, there was an error generating the answer.\"\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:45:59.809631Z","iopub.execute_input":"2024-08-27T09:45:59.810757Z","iopub.status.idle":"2024-08-27T09:45:59.819151Z","shell.execute_reply.started":"2024-08-27T09:45:59.810717Z","shell.execute_reply":"2024-08-27T09:45:59.818116Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#4094f7;  font-size: 22px;\">08. Recommendations Generation </span>\n\n<div style=\"font-size:16px; color:#FFAACF;\">\nUtilizes the Gemini API to provide unique and relevant resource recommendations based on a technical question. It delivers either courses or articles that aid in understanding the topic.\n</div>\n","metadata":{}},{"cell_type":"code","source":"def generate_recommendations_with_api(question):\n    \"\"\"Generate exactly three resource recommendations using the external API.\"\"\"\n    try:\n        model = genai.GenerativeModel('gemini-pro')\n        prompt = (f\"Based on the following technical question, provide exactly three unique and relevant \"\n                  \"courses without links if it‚Äôs a course; just mention the website and the name of the course, \"\n                  \"or articles that would help in understanding the topic, without any repetition:\\n\\n\"\n                  f\"Question: {question}\")\n        response = model.generate_content(prompt) \n        \n        return response.text\n    except Exception as e:\n        print(f\"Error generating recommendations with API: {e}\")\n        return \"Sorry, there was an error generating recommendations.\"","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:45:59.820542Z","iopub.execute_input":"2024-08-27T09:45:59.820916Z","iopub.status.idle":"2024-08-27T09:45:59.830627Z","shell.execute_reply.started":"2024-08-27T09:45:59.820880Z","shell.execute_reply":"2024-08-27T09:45:59.829540Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#4094f7; font-size: 22px;\">09. Smart Interview Generator</span>\n","metadata":{}},{"cell_type":"code","source":"def technical_interview(Category):\n    \"\"\"Conduct an interview based on experience level.\"\"\"\n    # Normalize the input Category\n    category_mapping = {\n        'fresh': ['fresh', 'junior', 'entry level'],\n        'intermediate': ['intermediate', 'mid', 'mid level'],\n        'senior': ['senior']\n    }\n\n    # Find the matching category\n    normalized_category = None\n    for key, values in category_mapping.items():\n        if Category.lower() in values:\n            normalized_category = key\n            break\n\n    if normalized_category is None:\n        print(\"Invalid Category. Please choose from 'fresh', 'intermediate', or 'senior'.\")\n        return\n    \n    # Filter questions based on the normalized Category\n    filtered_questions = train_df[train_df['Category '] == normalized_category]\n    \n    # Sample a number of questions based on the normalized Category\n    if normalized_category == 'fresh':\n        num_questions = 3\n    elif normalized_category == 'intermediate':\n        num_questions = 5\n    elif normalized_category == 'senior':\n        num_questions = 7\n    \n    selected_questions = filtered_questions.sample(n=min(num_questions, len(filtered_questions)))\n    \n    # Conduct the interview\n    for index, row in selected_questions.iterrows():\n        question = row['Questions']\n        print(f\"Question: {question}\")\n        \n        # Get answer from  API\n        answer = generate_answer_with_api(question)\n        print(\"\\nAnswer:\")\n        print(answer)\n        \n        # Provide recommended courses or articles\n        recommendations = generate_recommendations_with_api(question)\n        print(\"\\nRecommended Resources:\")\n        print(recommendations)\n        \n        print(\"\\n\" + \"-\"*50 + \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:45:59.831980Z","iopub.execute_input":"2024-08-27T09:45:59.832368Z","iopub.status.idle":"2024-08-27T09:45:59.846505Z","shell.execute_reply.started":"2024-08-27T09:45:59.832333Z","shell.execute_reply":"2024-08-27T09:45:59.845440Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#4094f7; font-size: 22px;\">10. Interview Time  </span>\n\n\n<div style=\"font-size:16px; color:#FFAACF;\">\n   And Now!!<br>\n    \nEnter your experience level üëÄ and get ready with impactful interview questions and answers‚ú®\n</div>\n","metadata":{}},{"cell_type":"code","source":"Category = 'junior' #input(\"Enter the Your Experience level (e.g., junior, mid, senior): \")\ntechnical_interview(Category)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:45:59.847785Z","iopub.execute_input":"2024-08-27T09:45:59.848218Z","iopub.status.idle":"2024-08-27T09:46:24.628189Z","shell.execute_reply.started":"2024-08-27T09:45:59.848182Z","shell.execute_reply":"2024-08-27T09:46:24.627060Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Question: What is randonm forest and how can you differentiate with other classification algorithm\n\nAnswer:\nRandom Forest Algorithm\n\nRandom Forest is a supervised machine learning algorithm that combines multiple decision trees to improve prediction accuracy and prevent overfitting. It works as follows:\n\n1. Bootstrapping: A random sample (with replacement) is drawn from the original training set multiple times.\n2. Decision Tree Construction: A decision tree is built using each bootstrap sample. Tree growth is limited to a random subset of features at each split.\n3. Voting: Each data point is predicted by each of the decision trees constructed. The majority prediction becomes the final prediction of the Random Forest.\n\nDifferentiation from Other Classification Algorithms\n\n1. Support Vector Machines (SVMs)\n\n* Similarities: Both are supervised classification algorithms that can handle non-linear data.\n* Differences:\n  * SVMs find the optimal decision boundary using a kernel function, while Random Forests use multiple decision trees.\n  * Random Forests are often more robust to noisy data and can handle high-dimensional datasets better.\n\n2. Logistic Regression\n\n* Similarities: Both are binary classification algorithms.\n* Differences:\n  * Logistic regression uses a sigmoid function to predict probabilities, while Random Forests use majority voting.\n  * Random Forests can handle more complex and non-linear relationships between features and the target variable.\n\n3. Naive Bayes\n\n* Similarities: Both are probabilistic classification algorithms.\n* Differences:\n  * Naive Bayes assumes feature independence, while Random Forests do not.\n  * Random Forests can be more accurate when feature dependencies exist.\n\n4. Decision Trees\n\n* Similarities: Both use decision trees for classification.\n* Differences:\n  * Random Forests combine multiple decision trees to reduce bias and improve accuracy.\n  * Random Forests prevent overfitting by limiting tree growth and using random feature subsets.\n\n5. Gradient Boosting Machines (GBMs)\n\n* Similarities: Both are ensemble methods that build multiple models sequentially.\n* Differences:\n  * GBMs use weighted data points and sequential tree construction to optimize a loss function, while Random Forests use majority voting.\n  * Random Forests typically perform better on high-dimensional datasets with complex relationships.\n\nRecommended Resources:\n1. Coursera: Machine Learning Specialization\n2. Udacity: Intro to Machine Learning\n3. Wikipedia: Random Forest\n\n--------------------------------------------------\n\nQuestion: What is ‚Äòtraining Set‚Äô and ‚Äòtest Set‚Äô in a Machine Learning Model? How Much Data Will You Allocate for Your Training, Validation, and Test Sets?\n\nAnswer:\nTraining Set, Validation Set, and Test Set\n\nIn machine learning, a dataset is divided into three parts:\n\n* Training Set: Used to train the machine learning model. The model learns patterns and relationships from this data.\n* Validation Set: Used to tune the model's hyperparameters (e.g., learning rate, number of epochs). It helps to select the best model configuration and avoid overfitting or underfitting.\n* Test Set: Used to evaluate the final model's performance on unseen data. It provides an unbiased assessment of the model's generalization ability.\n\nData Allocation\n\nThe allocation of data to these sets depends on the specific dataset and the complexity of the machine learning task. Generally, the following guidelines are followed:\n\n* Training Set: Typically the largest subset, representing 60-80% of the entire dataset.\n* Validation Set: A small to medium subset, often about 10-20% of the dataset.\n* Test Set: The smallest subset, usually around 10-20% of the dataset.\n\nImportance of Data Allocation\n\nProper data allocation is crucial for:\n\n* Avoiding Overfitting: A model trained on a large training set may overfit to specific patterns in that data and fail to generalize well to unseen data.\n* Selecting Optimal Hyperparameters: The validation set helps fine-tune the model's hyperparameters to maximize its performance.\n* Unbiased Performance Evaluation: The test set provides an independent assessment of the model's ability to handle real-world data.\n\nFactors to Consider\n\nWhen making data allocation decisions, consider the following factors:\n\n* Dataset Size: Larger datasets allow for more robust training but may require a larger validation and test set.\n* Model Complexity: More complex models may require a larger training set to learn the necessary relationships.\n* Data Availability: In some cases, data may be limited, which affects the sizes of the training, validation, and test sets.\n\nRecommended Resources:\n1. **Coursera: Machine Learning Specialization**\n2. **Article: Understanding Training and Test Sets in Machine Learning**\n3. **Article: How Much Data Should You Allocate for Training, Validation, and Test Sets?**\n\n--------------------------------------------------\n\nQuestion: What is Time series?\n\nAnswer:\nTime Series\n\nA time series is a sequence of data points taken at regular intervals over time. Each data point typically consists of a numerical value (e.g., temperature, stock price, website traffic) and a corresponding timestamp.\n\nKey Characteristics:\n\n* Ordered: Data points are arranged in chronological order.\n* Equally Spaced: The intervals between data points are consistent.\n* Time-Dependent: The value of a data point depends on the time it was measured.\n\nTypes of Time Series:\n\n* Univariate: Series containing only one variable (e.g., daily temperatures).\n* Multivariate: Series containing multiple variables (e.g., temperature, humidity, wind speed).\n* Stationary: Series with statistical properties that do not change over time (e.g., average temperature).\n* Non-Stationary: Series with statistical properties that vary over time (e.g., stock prices).\n\nUses of Time Series:\n\nTime series data is widely used in various fields, including:\n\n* Forecasting: Predicting future values based on historical patterns.\n* Trend Analysis: Identifying long-term trends in data.\n* Anomaly Detection: Detecting unusual or significant changes in data.\n* Event Modeling: Analyzing the timing and duration of events (e.g., machine breakdowns).\n* Seasonality Analysis: Identifying periodic patterns in data (e.g., daily, weekly, or seasonal variations).\n\nBuilding and Analyzing Time Series Models:\n\nTime series models are statistical models that capture the underlying structure and patterns in time series data. Common model types include:\n\n* Autoregressive Integrated Moving Average (ARIMA)\n* Seasonal Autoregressive Integrated Moving Average (SARIMA)\n* Holt-Winters Exponential Smoothing\n\nTime series analysis involves:\n\n* Data Preprocessing: Cleaning, transforming, and normalizing data.\n* Model Building: Selecting and fitting an appropriate time series model to the data.\n* Model Validation: Evaluating the model's performance on unseen data.\n* Forecasting: Predicting future values using the fitted model.\n\nRecommended Resources:\n1. Coursera: Time Series Analysis and Forecasting\n2. YouTube: Machine Learning Mastery - Time Series Forecasting with Python\n3. Towards Data Science: A Beginner's Guide to Time Series Data Analysis\n\n--------------------------------------------------\n\n","output_type":"stream"}]}]}